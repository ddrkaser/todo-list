The Model Risk Management and Control (MRMC) department has expressed concerns that the impact of the extended scoring scale on the designed rule coverage has not been adequately assessed by the Model Office (MO). According to the "Customized Scales in Qand_A Actimize_initial_validation" documentation, MO has stated that the alert score thresholds, or scoring scale, were expert-driven, signifying they were intentionally set based on expert judgment rather than purely on descriptive statistics. MO acknowledged that for some rules, the intentional misalignment between the scoring scale and rule thresholds was due to percentile values not correlating with the designed coverage of the rule. This suggests that the scoring scale was deliberately configured by experts to prioritize the designed rule coverage over specific thresholds. However, the documentation lacks sufficient justification for how changes to the scoring scale would impact the designed rule coverage.

There are concerns that this approach might not capture additional suspicious activities, potentially resulting in unnecessary alert breaks or false positives, leading to inefficiencies in the model. In the document "FS_SCORING_ANALYSIS_Updated [064]," a lookback analysis conducted by MO from February 2021 to January 2024 on the 12 affected rules aimed to identify any significant alerts missed due to the scoring gap. MRMC notes that historical productivity data is only available at the alert-break level and not at a rule-infraction level. Although no additional alert breaks were identified in the gap, the absence of a detailed analysis at the rule level means the impact of the extended scoring scale on capturing incremental Anti-Money Laundering (AML) risks remains unclear. The test results also support MRMC's observation that the original scoring scale functioned as intended and did not overlook any suspicious activities within its designed coverage.

Furthermore, in Table 42, several parameters have been reduced by more than 70% without sufficient justification in terms of conceptual soundness and a lack of thorough testing on the overall model performance.
